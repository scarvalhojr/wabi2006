\documentclass{llncs}
\usepackage{graphicx}
\usepackage{float}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Options for package float
\floatstyle{ruled}
\floatname{algorithm}{Algorithm}
\newfloat{algorithm}{t}{}

%% Our own commands
\newcommand{\ignore}[1]{}
\newcommand{\textR}{\raisebox{.6ex}{\scriptsize \textregistered}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Improving Oligonucleotide Microarray Layout Algorithms: Pivot Partitioning}
\titlerunning{Improving Microarray Layout: Pivot Partitioning}

\author{S\'ergio A. de Carvalho Jr.\inst{1,}\inst{2}\inst{,3} \and Sven Rahmann\inst{1,}\inst{3}}
\authorrunning{S.~A.~de Carvalho Jr.~and S.~Rahmann}
\tocauthor{Sergio A.~de Carvalho Jr.\ (Universit\"{a}t Bielefeld),
Sven Rahmann (Universit\"{a}t Bielefeld)}

\institute{
International NRW Graduate School in Bioinformatics and Genome Research
\and
Graduiertenkolleg Bioinformatik, Bielefeld University, Germany \\
\email{Sergio.Carvalho@cebitec.uni-bielefeld.de}
\and
Algorithms and Statistics for Systems Biology group, Genome Informatics,
Technische Fakult\"at, Bielefeld University, D-33594 Bielefeld, Germany \\
\email{Sven.Rahmann@cebitec.uni-bielefeld.de}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
The production of commercial DNA microarrays is based on a
light-directed chemical synthesis driven by a set of masks or
micromirror arrays. Because of the natural properties of light and the
ever shrinking feature sizes, the arrangement of the probes on the
chip and the order in which their nucleotides are synthesized play an
important role on the quality of the final product. We propose a new
model called \emph{conflict index} for evaluating microarray layouts.
%TODO XXX
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}

An oligonucleotide microarray is a piece of glass or plastic on which
single-stranded fragments of DNA, called \emph{probes}, are affixed or
synthesized. Affymetrix GeneChip\textR\ arrays, for instance, can contain more
than one million spots as small as 11 $\mu$m, with each spot accommodating
several million copies of a probe. Probes are typically 25 nucleotides long
and are synthesized on the chip, in parallel, in a series of repetitive steps.
Each step appends the same nucleotide to probes of selected regions of the
chip. Selection occurs by exposure to light with the help of a
photolithographic mask that allows or obstructs the passage of light
accordingly \cite{FODOR91}.

Formally, we have a set of probes $\mathcal{P} = \{p_{1}, p_{2}, ... p_{n}\}$
that are produced by a series of masks $\mathcal{M} = (m_{1}, m_{2}, ...
m_{\mu})$, where each mask $m_{k}$ induces the addition of a particular
nucleotide $t_{k} \in \{A, C, G, T\}$ to a subset of~$\mathcal{P}$. The
\emph{nucleotide deposition sequence} $\mathcal{S} = t_{1} t_{2} \ldots
t_{\mu}$ corresponding to the sequence of nucleotides added at each masking
step is therefore a supersequence of all $p_{i} \in \mathcal{P}$
\cite{RAHMANN03}.

In general, a probe can be \emph{embedded} within $\mathcal{S}$ in several
ways. An embedding of $p_{i}$ is a $\mu$-tuple
$\varepsilon_{i} = (e_{i,1}, e_{i,2}, ... e_{i,\mu})$ in which $e_{i,k} = 1$
if probe $p_{i}$ receives nucleotide $t_{k}$ (at step~$k$), or 0 otherwise
(Fig.~\ref{fig:masking_process}). In particular, a \emph{left-most embedding}
is an embedding in which the bases are synthesized as early as possible
(see $\varepsilon_8$ in Fig.\,\ref{fig:masking_process}).

\begin{figure}
\centerline{\includegraphics[width=230pt]{chip}}
\caption{Synthesis of a hypothetical 3$\times$3 chip. Top left: chip
layout and the 3~nt probe sequences. Top right: deposition
sequence and probe embeddings. Bottom: first four resulting masks.}
\label{fig:masking_process}
\vspace*{-2ex}
\end{figure}

The deposition sequence is often taken as a repeated permutation of the
alphabet, mainly because of its regular structure and because such sequences
maximize the number of distinct subsequences \cite{CHASE76}.  

We distinguish between \emph{synchronous} and \emph{asynchronous} embeddings.
In the first case, each probe has exactly one nucleotide synthesized in every
cycle of the deposition sequence; hence, 25 cycles or 100 steps are needed to
synthesize probes of length 25.  In the case of asynchronous embeddings,
probes can have any number of nucleotides synthesized in any given cycle,
allowing shorter deposition sequences. All Affymetrix chips that we know of
can be asynchronously synthesized in 74 steps (18.5 cycles), which is probably
due to careful probe selection.

Because of diffraction of light or internal reflection, untargeted spots can
be accidentally activated in a certain masking step, producing unpredicted
probes that can compromise experimental results. This problem is more likely
to occur near the borders between masked and unmasked spots~\cite{FODOR91}.
This observation has given rise to the term \emph{border conflict}.


We are interested in finding an \emph{arrangement} of the probes on the chip
together with \emph{embeddings} in such a way that the chances of unintended
illumination during mask exposure steps are minimized. The problem appears to
be hard because of the exponential number of possible arrangements, although
we are not aware of an NP-hardness proof.  In a separate
work~\cite{CARVALHO06}, we presented a formulation of the above problem as a
quadratic assignment problem (QAP), a classical combinatorial optimization
problem that is, in general, NP-hard and particularly hard to solve in
practice \cite{CELA98}. Optimal solutions are thus unlikely to be found even
for small chips and even if we assume that all probes have a single predefined
embedding. If we consider all possible embeddings (up to several million for a
typical Affymetrix probe), the problem is even harder.


For this reason, the problem has been traditionally tackled in two phases.
First, an initial embedding of the probes is fixed and an arrangement of these
embeddings on the chip with minimum border conflicts is sought. This is
usually referred to as the \emph{placement}. Second, a \emph{post-placement}
optimization phase re-embeds the probes considering its location on the chip,
in such a way that the conflicts with the neighboring spots are further
reduced.

It seems intuitive that better results should be achieved if the placement and
embedding phases are considered together, not separately. Because of the
generally high number of embeddings of each single probe in the asynchronous
setting, it is not easy to design algorithms that make efficient use of this
additional freedom and achieve reasonable running times in practice. In fact,
so far we know of no single publication that merges the two phases; in this
article we propose such a strategy called \emph{pivot partitioning}.


The rest of this paper is structured as follows. Section~\ref{sec:eval}
details two different ways of evaluating computed layouts and embeddings; they
form the objective functions that we aim to minimize. As a refinement of the
``classical'' border length of photolithographic masks, we introduce the
\emph{conflict index}. Section~\ref{sec:previous_work} reviews some of the
existing placement and post-placement strategies.  XXX
% TODO finish this paragraph

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Evaluating Layouts and Embeddings}
\label{sec:eval}

\paragraph{Border length.}
Hannenhalli and co-workers \cite{HANNENHALLI02} were the first to give a
formal definition of the problem of unintended illumination in the production
of microarrays. They formulated the \emph{Border Length Minimization Problem}
which aims at finding an arrangement of the probes together with their
embeddings in such a way that the number of border conflicts during mask
exposure steps is minimal.

The \emph{border length}~$\mathcal{B}_k$ of a mask~$m_{k}$ is defined as the
number of borders shared by masked and unmasked spots at masking step~$k$. The
total border length of a given arrangement is the sum of border lengths over
all masks. For example, the initial four masks shown in
Fig.\,\ref{fig:masking_process} have $\mathcal{B}_1 = 4$, $\mathcal{B}_2 = 6$,
$\mathcal{B}_3 = 6$ and $\mathcal{B}_4 = 4$.  The total border length of that
arrangement is 50.



\paragraph{Conflict Index.}
The border length of an individual mask measures the quality of that
mask. We are more interested in estimating the risk of synthesizing a faulty
probe at a given spot, that is, we need a per-spot measure
instead of a per-mask measure. Additionally \cite{KAHNG03A},
the definition of border length does not take into account two
simple yet important practical considerations:
\begin{itemize}
\item[a)] stray light might activate not only adjacent neighbors but
  also probes that lie as far as three cells away from the targeted
  spot;
\item[b)] imperfections produced in the middle of a probe are more
  harmful than in its extremities.
\end{itemize}
This motivates the following definition of the \emph{conflict
  index}~$\mathcal{C}(s)$ of a spot~$s$ whose probe of
length~$\ell_{s}$ is synthesized in $\mu$~masking steps. First, we
define a distance-dependent weighting function, $\delta(s,s',k)$, that
accounts for observation a) above:
%%
\begin{equation}
\label{eq:dist_weight}
\delta(s,s',k) :=
        \left\{
                \begin{array}{ll}
                        (d(s,s'))^{-2} & \mbox{if $s'$ is unmasked at step $k$}, \\
                        0 & \mbox{otherwise}, \\
                \end{array}
        \right.
\end{equation}
%%
where $d(s,s')$ is the Euclidean distance between spots~$s$ and~$s'$.
This form of weighting function is the same as suggested in
\cite{KAHNG03A}.  Note that $\delta$ is a ``closeness'' measure
between $s$ and $s'$ only if $s'$ is
not masked (and thus creates the potential of illumination at $s$). To
restrict the number of neighbors that need to be considered, we
restrict the support of $\delta(s,s',\cdot)$ to those $s'\neq s$ that
are in a $7\times 7$ grid centered around $s$ (see
Fig.\,\ref{fig:conflictindex}~top).


We also define position-dependent weights to account for observation b):
%%
\begin{equation}\label{eq:pos_mult}
\omega(s,k) :=
\left\{
  \begin{array}{ll}
    c \cdot \exp{\left(\theta \cdot \lambda(s,k)\right)} & \mbox{if $s$ is masked at step $k$}, \\
    0 & \mbox{otherwise}, \\
  \end{array}
\right.
\end{equation}
%%
where $c>0$ and $\theta>0$ are constants, and
%%
\begin{equation}\label{eq:base_pos}
  \lambda(s,k) := 1 + \min(b_{s,k},\ell_{s} - b_{s,k})
\end{equation}
%%
is the distance of the probe length after $k$ synthesis steps
from the start or end of the final probe: $b_{s,k}$ denotes the number of
nucleotides synthesized at spot~$s$ up to and including step~$k$, and
$\ell_s$ is the probe length (see Fig.\,\ref{fig:conflictindex}
bottom).

The motivation behind an exponentially increasing weighting function is that
the probability of a successful stable hybridization of a probe with its
target should increase exponentially with the absolute value of its Gibbs free
energy, which increases linearly with the length of the longest perfect match
between probe and target. The parameter $\theta$ controls how steeply the
exponential weighting function rises towards the middle of the probe.
%
\ignore{It is generally agreed that the chances of a successful hybridization
  between probe and target are higher if a mismatched base occurs at the
  extremities of the formed duplex instead of at its center. The precise
  effects of this position, however, is not yet fully understood and has been
  an active topic of research \cite{BINDER05}.}
%
In our experiments, we set $\theta := 5/\ell_s$ and $c = 1/\exp{\theta}$.


We define the conflict index of a spot $s$ as
\begin{equation}
\label{eq:conf_idx}
\mathcal{C}(s) := \sum_{k=1}^{\mu} \left( \omega(s,k) \sum_{s'} \delta(s,s',k) \right),
\end{equation}
%%
where $s'$ ranges over all spots that are at most three cells away
from $s$.  $\mathcal{C}(s)$ can be interpreted as the fraction of
faulty probes (because of unwanted illumination) produced at spot $s$.

\begin{figure}
\centerline{
%%
\begin{picture}(160,105)
\put(0,23){\makebox(160,80){
\begin{minipage}{160pt}
\centerline{\footnotesize{
\begin{tabular}{|c|c|c|c|c|c|c|c|} \hline
\ 0.06\ & \ 0.08 & \ 0.10 & \ 0.11 & \ 0.10 & \ 0.08 & \ 0.06 \\ \hline
\ 0.08\ & \ 0.13 & \ 0.20 & \ 0.25 & \ 0.20 & \ 0.13 & \ 0.08 \\ \hline
\ 0.10\ & \ 0.20 & \ 0.50 & \ 1.00 & \ 0.50 & \ 0.20 & \ 0.10 \\ \hline
\ 0.11\ & \ 0.25 & \ 1.00 &    s   & \ 1.00 & \ 0.25 & \ 0.11 \\ \hline
\ 0.10\ & \ 0.20 & \ 0.50 & \ 1.00 & \ 0.50 & \ 0.20 & \ 0.10 \\ \hline
\ 0.08\ & \ 0.13 & \ 0.20 & \ 0.25 & \ 0.20 & \ 0.13 & \ 0.08 \\ \hline
\ 0.06\ & \ 0.08 & \ 0.10 & \ 0.11 & \ 0.10 & \ 0.08 & \ 0.06 \\ \hline
\end{tabular}}}
\end{minipage}}}
\end{picture}
%%
\begin{picture}(190,105)
\footnotesize{
\put(0,0){\makebox(190,105){
  \input{position_weights}
}}}
\end{picture}
%%
}
%\vspace*{-3ex}
\caption{Ranges of values for both $\delta$ and $\omega$ on a typical 
  Affymetrix chip where probes of length~$\ell = 25$ are synthesized in $\mu =
  74$ masking steps. Left: approximate values of the distance-dependent
  weighting function $\delta(s,s',k)$ for a spot~$s$ (shown in the center) and
  close neighbors $s'$, assuming that $s'$ is unmasked at step $k$. Right:
  position-dependent weights $\omega(s,k)$ at each value of $b_{s,k}$,
  assuming that spot $s$ is masked at step $k$.}
\label{fig:conflictindex}
\end{figure}

The following relation between conflict indices and border lengths holds when
we define $\delta(s,s',k):=1$ if $s'$ is a direct neighbor of $s$ and is
unmasked in step $k$, and $:=0$ otherwise, and $\omega(s,k):=1$ if $s$ is
masked in step $k$, and $:=0$ otherwise: Then $\sum_s\, \mathcal{C}(s) = 2
\sum_{k=1}^\mu\, \mathcal{B}_k$, as each border conflict is counted twice,
once for $s$ and once for $s'$. Therefore border length and total conflict are
equivalent for a particular choice of $\delta$ and $\omega$. For our
choice~(\ref{eq:dist_weight}) and~(\ref{eq:pos_mult}), they are not
equivalent, but still correlated: A good layout has both low border length and
low average conflict index.


% ==============================================================================
\section{Previous Work}
\label{sec:previous_work}

The border length problem on large oligonucleotide arrays of arbitrary probes
was first formally addressed in~\cite{HANNENHALLI02}. The article reports that
the first Affymetrix chips were designed using a heuristic for the traveling
salesman problem (TSP). The idea consists of building a weighted graph with
nodes representing probes, and edges containing the Hamming distance between
the probe sequences. A TSP tour is approximated, resulting in consecutive
probes in the tour being likely to be similar. The TSP tour is then
\emph{threaded} on the array in a row-by-row fashion.  \cite{HANNENHALLI02}
suggests a different threading of the TSP tour on the chip, called
\emph{1-threading}, to achieve up to 20\% reduction in border length.

% old version of paragraph about Epitaxial alg.
\ignore{
Kahng~{\it et~al}.~\cite{KAHNG02} propose the \emph{Epitaxial} placement algorithm that
places a random probe in the center of the array and continues to
insert probes in spots adjacent to already filled spots, employing a
greedy heuristic to select the next spot to be filled and the probe
that is assigned to it. Priority is given to spots whose
neighbors are already filled, in which case the algorithm places the
probe with minimum sum of Hamming distances to its neighbors. If no
such a spot exists, the algorithm examines all non-filled spots~$s_i$
with $n_i \geq 1$ filled neighbors and finds a non-assigned probe
$p_j$ with minimum sum of Hamming distances to the neighboring probes
$H_{ij}$. For each possible assignment of $p_j$ to $s_i$, it computes
a cost $c(s_i,p_j) := k_{n_i} H_{ij} / n$, where $k_{n_i}$ are scaling
coefficients ($k_1 = 1$, $k_2 = 0.8$, and $k_3 = 0.6$), and makes the
assignment with minimum cost. With this algorithm, they claimed to
achieve up to 10\% reduction in border conflicts over the TSP-based
approach of Hannenhalli~{\it et~al}.\ \cite{HANNENHALLI02}.
}

A different strategy called the \emph{Epitaxial} placement algorithm
\cite{KAHNG02} places a random probe in the center of the array and continues
to insert probes in spots adjacent to already filled spots. Priority is given
to spots with the largests numbers of filled neighbors. At each iteraction, it
examines all non-filled spots~$s_i$ and finds a non-assigned probe $p_j$ with
minimum sum of Hamming distances to the neighboring probes $H_{ij}$, employing
a greedy heuristic to select the next spot to be filled.  A further 10\%
reduction in border conflict over TSP~+~1-threading is claimed.

\ignore{
The major problem with the Epitaxial and the TSP-based algorithm is that they
have at least quadratic time complexity and thus are not scalable for the
latest million-probe microarrays. According to their experiments, the TSP
approach needed around 32 minutes to produce the layout of a 200\,x\,200
chip, whereas the Epitaxial algorithm needed 74 minutes on average. For a
500\,x\,500 chip, the TSP took over 30 hours to complete, whereas the
Epitaxial algorithm did not complete ``due to prohibitively large running
time or memory requirements'' \cite{KAHNG02}.
}

\ignore{
This observation has led to the development of two new algorithms by
\cite{KAHNG03A}. The first one, called Sliding-window Matching (SWM), is not
exactly a placement algorithm as it iteratively improves an initial placement
that can be constructed by, for instance, TSP and 1-threading. Improvements
are achieved by selecting an independent set of spots inside the window and
optimally replacing their probes using a minimum-weight perfect matching
algorithm. The term independent refers to probes that can be replaced without
affecting the border length of the other selected probes.
}

Both the Epitaxial algorithm and the TSP approach do not scale well to large
chips. For this reason, \cite{KAHNG03A} proposes a simpler variant of the
Epitaxial algorithm, called \emph{Row-epitaxial}, with two main differences:
spots are filled in a pre-defined order, namely from top to bottom, left to
right, and only probes of a limited list of candidates are considered when
filling each spot. Experiments show that Row-epitaxial is the best
large-scale placement algorithm, achieving up to 9\% reduction in border
length over the TSP+1-threading.


\paragraph{Partitioning Algorithms.}
The placement problem can be partitioned by dividing the set of probes into
smaller sub-sets, and assigning these sub-sets to sub-regions of the chip.
Each sub-region can then be treated as an independent chip or recursively
partitioned. These smaller sub-problems, when solved, immediately constitute a
final solution. In this way, algorithms with non-linear time or space
complexities can be used to compute the layout of larger chips that otherwise
would not be feasible.

The only partitioning algorithm that we know of is Centroid-based
Quadrisection (CQ)~\cite{KAHNG03B}. It starts by randomly selecting a probe
$c_1 \in \mathcal{P}$. Then, it selects another probe $c_2$ maximizing
$h(c_1,c_2)$, the Hamming distance between their embeddings. Similarly, it
selects $c_3$ and $c_4$ maximizing the sum of Hamming distance between these
four probes, that are called centroids. All other probes $p_i \in \mathcal{P}$
are then compared to the centroids and assigned to the sub-set $\mathcal{P}_j$
associated with $c_j$ with minimum $h(p_i,c_j)$. The chip is divided into four
quadrants, each being assigned to a sub-set $\mathcal{P}_j$ .  The procedure
is repeated recursively on each quadrant until a given recursion depth is
reached. In the end, the Row-epitaxial algorithm is used to produce the
placement of the probes in each final sub-region.


\paragraph{Post-placement Optimization.}
Once the placement is done, further reduction of conflicts can be achieved by
re-embedding the probes without changing their locations.  The paper
\cite{KAHNG02} presents a dynamic programming algorithm, that we call Optimum
Single Probe Embedding (OSPE), for computing an optimum embedding of a probe
on a spot $s$ with respect to the probes of neighboring spots, whose
embeddings are considered fixed.  Originally, it was developed for border
length minimization; below (Sect.~\ref{sec:ospe} we give a slightly more
general form that also applies to the conflict index measure.

The OSPE algorithm is the basic operation of several post-placement
optimization algorithms: Batched Greedy~\cite{KAHNG02},
Chessboard~\cite{KAHNG02} and Sequential~\cite{KAHNG03B}. Their main
difference lies in the order in which the re-embeddings take place.

\ignore{ The first algorithm is a simple greedy approach that computes, for
  each spot of the chip, the maximum reduction of conflicts that could be
  achieved by re-embedding its probe with the OSPE algorithm. It then greedily
  selects the spot with higher gain and re-embeds its probe optimally with
  respect to its neighbors, updating the gains of affected spots. A faster
  version, called Batched Greedy, sacrifices its greedy nature by postponing
  the update of gains and re-embedding all probes that have not been affected
  by the re-embeddings performed in the current iteration.
  
  The Chessboard optimization is based on the fact that a chip can be
  bi-colored just like a chessboard, in such a way that the embeddings of
  probes located on white spots, with respect to border length, are
  independent of those placed on black spots, and vice-versa. The Chessboard
  uses this coloring to alternate the optimal re-embedding of probes located
  on black and white spots.%
}

The Sequential algorithm is a simple but so far the most effective
post-placement optimization. It just proceeds spot by spot, from top to
bottom, left to right, re-embedding all probes with the OSPE algorithm.
Surprisingly, it achieves the greatest reduction of border conflicts with a
running time compared to the Batched Greedy, the faster among the three.

The OSPE algorithm never increases the amount of conflicts in a region.  All
optimization algorithms can thus be executed several times until a local
optimal solution is found, or until the improvements drop below a given
threshold.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Optimum Single Probe Embedding}
\label{sec:ospe}

The Optimum Single Probe Embedding (OSPE) algorithm finds the optimal
embedding of a single probe on a given spot, assuming that all neighboring
embeddings are fixed. It can be seen as a special case of a global alignment
between the sequence $p$ of length $\ell$ and the deposition sequence
$\mathcal{S}$ of length $\mu$. We use an $(\ell + 1) \times (\mu + 1)$ array
$D$, where $D[i,j]$ is defined as the minimum cost of an embedding of
$p[1..i]$ into $\mathcal{S}[1..j]$.  The cost is the sum of conflicts induced
by the embedding of $p$ on its neighbors plus the conflicts suffered by $p$
because of the embeddings of its neighbors.

At every step $j$ of the deposition sequence, the spot $s$ can be either
masked or unmasked. Thus, entry $D[i,j]$ is computed as the minimum between
the costs resulting from each possible action:
%%
\[
D[i,j] = \min (D[i,j-1] + M_{ij}, D[i-1,j-1] + U_{j}).
\]
%%
The costs $M_{ij}$ and $U_{j}$ depend on the spot $s$ and the neighboring
spots $s'$:

$M_{ij}$ denotes the cost of masking spot $s$ at step $j$ given that base $i$
of probe $p$ has been synthesized previously.  Any unmasked neighbor $s'$
generates a conflict on $s$ with cost $\omega(s,i)\cdot \delta(s,s',j)$;
therefore the total cost is
\[ M_{ij} = \sum_{s'}\, \omega(s,i) \delta(s,s',j). \]

$U_{j}$ denotes the cost of unmasking spot $s$ at step $j$; it generates a
conflict on each masked neighbor $s'$ with cost $\omega(s',j)\cdot
\delta(s',s,j)$; therefore 
\[ U_j = \sum_{s'}\, \omega(s',j) \delta(s',s,j). \]

The first column of $D$ is initialized as follows: $D[0,0] = 0$ and $D[i,0] =
\infty$ for $0 < i \leq \ell$. The first row is $D[0,j] = D[0,j-1]+M_{0j}$ for
$0<j\leq\mu$.

The time complexity of the OSPE algorithm is obviously $O(\ell_p \cdot
|\mathcal{S}|)$, where $\ell_p$ is the length of probe $p$ and $|\mathcal{S}|$
is the length of the deposition sequence.


% ==============================================================================
\section{Pivot Partitioning}
\label{sec:pivotpart}

Traditionally, the microarray layout problem has been tackled in two phases:
placement, during which an initial embedding of the probes is fixed, and
post-placement optimization, when probes are re-embedded using the OSPE algorithm.
We believe that better layouts can be produced if the placement phase also considers
the various embeddings that a probe can have. In this section we propose a new
partitioning algorithm called Pivot Partitioning (PP).

Our algorithm
has some similarities with the Centroid-based Quadrisection (CQ) described
in Sect.\,\ref{sec:previous_work}.
Its main differences are motivated by the following observation.
As mentioned earlier, some probes can have up to several millions different
embeddings, while others may have only a few or even only one possible embedding.
Probes with more embeddings can better
``adapt'' to the other probes, that is, when placed on a spot, they are more likely
to have an embedding with fewer conflicts than a probe that has
only a limited number of embeddings.

We use the probes with fewer embeddings, that we call ``pivots'', to drive the
partitioning of the probe set and to re-embed the the probes just before their
placement (as a partitioning algorithm, the PP also works in combination with
another placement algorithm). Our algorithm works for border length minimization
as well as conflict index minimization.

\begin{algorithm}
\caption{Pivot Partitioning}
\label{alg:pivotpart}
\begin{minipage}{4.8in}

\begin{tabbing}
Output: \=                                  \kill
Input:  \> chip dimension,                          \\
        \> set of probes $\mathcal{P} = \{p_{1}, p_{2}, ... p_{n}\}$,       \\
        \> maximum partitioning depth $t_{max}$                 \\
Output: \> placement of the probes $p_i$ on the chip
\end{tabbing}

\begin{enumerate}
\item Select probes $p$ with minimum number of embeddings, $E(p)$,
as pivot candidates:
  \begin{enumerate}
  \item Let $\mathcal{Q} = \{p \in \mathcal{P} | E(p) = \min E(p_i) \forall p_i \in \mathcal{P} \}$
  \item Set $\mathcal{P} \leftarrow \mathcal{P} - Q$
  \end{enumerate}
\item Define a region $R$ of the chip containing all of its rows and columns
\item Call the Recursive Partitioning with the initial partitioning depth $t$:
  \begin{enumerate}
  \item Set $t \leftarrow 1$
  \item Call Recursive Partitioning ($t$, $t_{max}$, $R$, $\mathcal{Q}$, $\mathcal{P}$)
  \end{enumerate}
\end{enumerate}

\end{minipage}
\end{algorithm}

% ------------------------------------------------------------------------------
\subsection{Pivot Candidates}

The first step of the Pivot Partitioning (Algorithm\,\ref{alg:pivotpart}), is to
select the pivot candidates $\mathcal{Q}$, a set of probes that can later be
chosen as pivots. Our pivots are the equivalent of the centroids of the CQ
algorithm; they are used to partition the probe set. Their
selection, however, is restricted to the probes having the least number of
embeddings.

The reasons are two-fold. First, less time is spent choosing the pivots
since less candidates need to be examined.
Second, probes with fewer embeddings are better representatives to drive
the partitioning. The problem is that some embeddings have their unmasked steps
concentrated in one region of the deposition sequence. This is specially true if
the probes are embedded in a left-most fashion.
Some Affymetrix probes, for instance, in a
left-most embeddeding, can be synthesized in the first 37 masking steps, thus
using only half of the total 74 steps. Such probes are clearly not good choices
for pivots. Probes with the minimum number of embeddings, on the other hand,
are guaranteed to cover most (if not all) cycles of the deposition sequence,
and are thus a better choices for pivots.

In order to guarantee a good partitioning, $\mathcal{Q}$ must have a reasonable
amount of probes. This is because the pivots later chosen for the partitioning
must maximize the distance between their embeddings, just like in the CQ
algorithm. We thus limit the size of $\mathcal{Q}$ to a minimum of 1\% of the total
number of probes\footnote{Usually, around 1-2\% of the probes of an Affymetrix array
have only one possible embedding; or two, if we consider that they appear in PM/MM
pairs and must be ``aligned'' in all but the steps that synthesize their middle
bases}, which may force the selection of probes with the next minimum
number of embeddings.
Computing the number of embeddings of a probe takes $O(\ell \mu)$ time, where
$\ell$ is the length of the probe and $\mu$ is the length of the deposition sequence.
With a few simple optimizations, however, even a million probes can be examined in
a few minutes.

% ------------------------------------------------------------------------------
\subsection{Recursive Partitioning}

\begin{algorithm}
\caption{Recursive Partitioning}
\label{alg:recursivepart}
\begin{minipage}{4.8in}

\begin{tabbing}
Output: \=                                  \kill
Input:  \> current depth level $t$,                     \\
        \> maximum depth level $t_{max}$                    \\
        \> rectangular region $R$ of the chip,                  \\
        \> set of pivot candidates $\mathcal{Q}$,               \\
        \> set of probes $\mathcal{P}$,                     \\
Output: \> placement of the probes $p_i \in \mathcal{P}$ and
           $q_i \in \mathcal{Q}$ on the region $R$ of the chip
\end{tabbing}

\begin{enumerate}
\item If $t = t_{max}$ then
  \begin{enumerate}
    \item Re-embed $p_i \in \mathcal{P}$ optimally with respect to $\mathcal{Q}$
    \item Call Row-epitaxial ($R$, $\mathcal{P} \cup \mathcal{Q}$)
    \item Return
  \end{enumerate}
\item Choose pivot pair...
\item Partition the set of pivot candidates...
\item Partition the set of probes...
\item Partition the chip region...
\item Recursive calls...
\end{enumerate}

\end{minipage}
\end{algorithm}

The essence of the Pivot Partitioning algorithm is its recursive procedure
(Algorithm\,\ref{alg:recursivepart}), that is executed until a given maximum
recursion depth $t_{max}$ is reached. Its main arguments are the set of probes
$\mathcal{P}$, the set of pivot candidates $\mathcal{Q}$ and a rectangular region
of the chip $R$, which consists of a range of rows and columns.

Initially, a pair of pivots $q'$ and $q'' \in \mathcal{Q}$ is chosen among all
possible pairs of pivot candidates in such a way that the weighted distance between
their embeddings $wd(q', q'')$ is maximized. The weighted distance equals the
Hamming distance in case of border length minimization. In case of conflict index
minimization, the weigthed distance mimics the position-dependent weights $\omega$
defined in Sect.\,\ref{sec:conflict_index}. The embeddings of the pivots are
considered fixed; thus, computing $wd(q', q'')$ takes linear time on the length
of their embeddings.

The two pivots $q'$ and $q''$ are then used to divide the set $\mathcal{Q}$
by computing the weighted distance between the embeddings of $q_i \in \mathcal{Q}$
and the embeddings of the chosen pivots, assigning $q_i$ to $\mathcal{Q}'$ if
$wd(q_i, q') < wd(q_i, q'')$ or to $\mathcal{Q}''$ if $wd(q_i, q'') < wd(q_i, q')$.
In case of draws, the assignments are made in an attempt to
achieve balanced partitionings. Again, the distances are computed in linear time
since embeddings of pivot candidates are also considered fixed.

In the next step, the set $\mathcal{P}$ of probes is partitioned. For all probes
$p_i \in \mathcal{P}$, we compute the minimum weighted distance that any embedding
of $p_i$ can have to the embeddings of the pivots $q'$ and $q''$, assigning it to
one of the sub-set $\mathcal{P}'$ and $\mathcal{P}''$ associated with the pivot
with the minimum distance. This is done with a special version of the OSPE algorithm
that ignores the location of the probes.

After the partitioning of $\mathcal{P}$ and $\mathcal{Q}$, we can then divide the
region $R$ of the chip into two sub-regions $R'$ and $R''$, proportionally to the
number of probes in $\mathcal{Q}' \cup \mathcal{P}'$ and $\mathcal{Q}'' \cup \mathcal{P}''$.
We alternate between horizontal and vertical divisions at each partitioning depth $t$.
Since we only deal with rectangular regions, sometimes it is necessary to move
a few probes from one partition to the other in order to ensure that the probes
will fit in the sub-regions.

Each sub-region is then processed recursively. Once the maximum partitioning depth
$t_{max}$ is reached, the Row-epitaxial~\cite{KAHNG03A} algorithm is
called to place the probes of $\mathcal{P} \cup \mathcal{Q}$ in the region $R$.
Before that, however, all probes $p_i \in \mathcal{P}$ are re-embedded optimally
with respect to the pivots using a special version of the OSPE algorithm that treats
all pivots as immediate neighbors of $p_i$. This is done before the placement in
order to ``synchronize'' any skewed embeddings, and to finds an embedding of
$p_i$ that has minimum conflict with the ``average'' probe in $R$.

% ==============================================================================
\section{Results}
% ==============================================================================
\label{sec:results}

\begin{table}
\label{tab:pp_x_cq_bl}
\caption{Improvements of Pivot Partitioning (PP) over Centroid-based Quadrisection (CQ) with
varying partitioning depths. Border length comparison. After running Sequential
optimization. Chips with random probes, synchronously embedded.}
\centerline{\scriptsize{
\begin{tabular}{clrrlrrlrrlrr}
& & \multicolumn{1}{c}{CQ} & \multicolumn{1}{c}{PP} & & \multicolumn{1}{c}{CQ} & \multicolumn{1}{c}{PP} & & \multicolumn{1}{c}{CQ} & \multicolumn{1}{c}{PP} & & \multicolumn{1}{c}{CQ} & \multicolumn{1}{c}{PP} \\
\noalign{\smallskip}
Dim & & \multicolumn{1}{c}{$L=0$} & \multicolumn{1}{c}{$t_{max}=0$} & & \multicolumn{1}{c}{$L=1$} & \multicolumn{1}{c}{$t_{max}=2$} & & \multicolumn{1}{c}{$L=2$} & \multicolumn{1}{c}{$t_{max}=4$} & & \multicolumn{1}{c}{$L=3$} & \multicolumn{1}{c}{$t_{max}=6$} \\
\noalign{\smallskip}
\cline{1-1} \cline{3-4} \cline{6-7} \cline{9-10} \cline{12-13}
\noalign{\smallskip}
100 & & \   415,227 & \ -3.00\% & & \   393,218 & \ 0.16\% & & \   399,312 & \ -1.98\% & & \   410,608 & \ -2.87\% \\
200 & & \ 1,608,382 & \         & & \ 1,524,803 & \        & & \ 1,545,825 & \         & & \ 1,573,096 & \         \\
300 & & \ 3,529,745 & \         & & \ 3,493,552 & \        & & \ 3,413,316 & \         & & \ 3,434,964 & \         \\
500 & & \ 9,463,941 & \         & & \ 9,546,351 & \ 7.87\% & & \ 9,355,231 & \  4.67\% & & \ 9,307,510 & \  1.03\% \\
\noalign{\smallskip}
\hline
\end{tabular}}}
\end{table}

\begin{table}
\label{tab:pp_x_cq_time}
\caption{Reduction in running time of both Pivot Partitioning (PP) and Centroid-based Quadrisection (CQ) with
varying partitioning depths. Running time comparison of partitioning and placement only
(no post-placement optimization).}
\centerline{\scriptsize{
\begin{tabular}{clrrlrrlrrlrr}
& & \multicolumn{1}{c}{CQ} & \multicolumn{1}{c}{PP} & & \multicolumn{1}{c}{CQ} & \multicolumn{1}{c}{PP} & & \multicolumn{1}{c}{CQ} & \multicolumn{1}{c}{PP} & & \multicolumn{1}{c}{CQ} & \multicolumn{1}{c}{PP} \\
\noalign{\smallskip}
Dim & & \multicolumn{1}{c}{$L=0$} & \multicolumn{1}{c}{$t_{max}=0$} & & \multicolumn{1}{c}{$L=1$} & \multicolumn{1}{c}{$t_{max}=2$} & & \multicolumn{1}{c}{$L=2$} & \multicolumn{1}{c}{$t_{max}=4$} & & \multicolumn{1}{c}{$L=3$} & \multicolumn{1}{c}{$t_{max}=6$} \\
\noalign{\smallskip}
\cline{1-1} \cline{3-4} \cline{6-7} \cline{9-10} \cline{12-13}
\noalign{\smallskip}
100 & & \    108 & \   000 & & \ 36.1\% & \   000 & & \   399,312 & \   000 & & \   410,608 & \   000 \\
200 & & \  1,151 & \ 0,000 & & \    992 & \ 0,000 & & \ 1,545,825 & \ 0,000 & & \ 1,573,096 & \ 0,000 \\
300 & & \  3,671 & \ 0,000 & & \  3,529 & \ 0,000 & & \ 3,413,316 & \ 0,000 & & \ 3,434,964 & \ 0,000 \\
500 & & \ 10,630 & \ 0,000 & & \ 10,591 & \ 0,000 & & \ 9,355,231 & \ 0,000 & & \ 9,307,510 & \ 0,000  \\
\noalign{\smallskip}
\hline
\multicolumn{13}{c}{TODO: substitute time in seconds for a percentage of the time with no partitioning.}
\end{tabular}}}
\end{table}


\ignore{
Experiments were conducted on a Sun Fire V1280 server with 900Mhz UltraSparc III+ processors
and 96 Gb of RAM under similar load balances.
}

\ignore{Their results show that the running time of the Row-epitaxial algorithm
drops significantly with increasing recursion depth. The time required to place
the probes of a 500\,x\,500 chip, for instance, dropped by 69\% with $L = 3$ when
compared with the time required by the Row-epitaxial without any partitioning.

It is not clear from their experiments, however, how the choice of $L$ impaired
the performance of the Row-epitaxial algorithm in terms of solution quality since
they have restricted their experiments to $L \leq 3$. Moreover, there is no clear
trend toward reduction or increase in border length as $L$ varies from~0 to~3.}

% ==============================================================================
\section{Discussion}
% ==============================================================================
\label{sec:discuss}

A partitioning is clearly a compromise in solution quality, but
for large chips it can have little impact.

We believe that the main advantages of our
approach over the CQ algorithm are:

\begin{itemize}
\item faster and better selection of pivots used to drive
the assignment of probes to sub-regions;
\item improved assignment of probes to regions by considering all valid embeddings
of a probe;
\item simpler implementation.
\end{itemize}

\paragraph{Acknowledgments.}We thank Ion Mandoiu, Xu Xu and Sherief Reda for
providing an implementation of their algorithms.

% ==============================================================================
\begin{thebibliography}{5}
% ==============================================================================

\bibitem{BINDER05}
Binder, H., Preibisch, S.:
Specific and nonspecific hybridization of oligonucleotide probes on microarrays.
{\it Biophysical Journal} (2005) {\bf 89} 337--352.

\bibitem{CARVALHO06}
de Carvalho Jr., S., Rahmann, S.:
Modeling Microarray Layout as a Quadratic Assignment Problem.
Submitted (2006).

\bibitem[\c{C}ela, 1998]{CELA98} \c{C}ela,E. (1998) {\it The Quadratic Assignment Problem: Theory and Algorithms}. Kluwer, Massachessets, USA.


\bibitem{CHASE76}
Chase, P.:
Subsequence numbers and logarithmic concavity.
{\it Discrete Mathematics} (1976) {\bf 16} 123--140.

\ignore{
\bibitem{FELDMAN93}
Feldman, W., Pevzner, P.:
Gray code masks for sequencing by hibridization.
{\it Genomics} (1994) {\bf 23} 233--235.
}

\bibitem{FODOR91}
Fodor, S., Read, J., Pirrung, M., Stryer, L., Lu, A., Solas, D.:
Light-directed, spatially addressable parallel chemical synthesis.
{\it Science} (1991) {\bf 251} 767--73.

\bibitem{HANNENHALLI02}
Hannenhalli, S., Hubell, E., Lipshutz, R., Pevzner, P.:
Combinatorial algorithms for design of DNA arrays.
{\it Advances in Biochemical Engineering / Biotechnology} (2002) {\bf 77} 1--19.

\bibitem{KAHNG02}
Kahng, A., Mandoiu, I., Pevzner, P., Reda, S., Zelikovsky, A.:
Border length minimization in DNA array design.
In {\it Proceedings of the Second Workshop on Algorithms in Bioinformatics} (WABI 2002).

\bibitem{KAHNG03A}
Kahng, A., Mandoiu, I., Pevzner, P., Reda, S., Zelikovsky, A.:
Engineering a scalable placement heuristic for DNA probe arrays.
In {\it Proceedings of the Seventh Annual International Conference on Computational
Molecular Biology} (2003) 148--156.

\bibitem{KAHNG03B}
Kahng, A., Mandoiu, I., Reda, S., Xu, X., Zelikovsky, A.:
Evaluation of placement techniques for DNA probe array layout.
In {\it Proceedings of the IEEE/ACM International Conference on Computer-Aided Design}
(2003) 262--269.

\bibitem{RAHMANN03}
Rahmann, S.:
The shortest common supersequence problem in a microarray production setting.
In {\it Proceedings of the 2nd European Conference in Computational Biology}
({ECCB} 2003), volume 19 Suppl.~2 of {\it Bioinformatics}, pages ii156--ii161.

\end{thebibliography}

\end{document}
